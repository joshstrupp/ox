Note About This Draft  

The Smithsonian Institution (SI) intends to release a Statement of Qualification on FBO.gov on/around Thursday, Oct. 24. The SI requests comments, questions __and especially suggestioned edits__ about this Draft Statement of Qualification by 9:00AM EST on Tuesday, Oct. 22 via github or via email to Jill Roberts at RobertsJRJ2@si.edi and Brent Maravilla at bmaravilla@omb.eop.gov. With an eye on eventually obtaining quotes from vendors that approach technology in line with the Digital Services Playbook, we want to understand how this exercise is either not stringent enough or too stringent.

__DRAFT STATEMENT OF QUALIFICATION__  

The Smithsonian Institution (SI) intends to release a Request for Proposal on or around 11/1/2019 for a Digital Minimum Viable Product for Slavery and Freedom. Interested vendors shall follow the steps below. This posting is not a Request for Proposal. The purpose of this Statement of Qualification is to encourage participation in this procurement from only those vendors who have a solid commitment to building technology for their government clients according to the Digital Services Playbook. Vendors who may not yet have this commitment are strongly DISCOURAGED to respond because they are not the best fit.

1. Respond with a 1-page Statement of Qualifications via email to (fill in here) by 15 calendar days of this posting (by 9:00AM EST).  
2. For background information, see the draft Statements of Objectives, the draft Request for Proposal, and other additional information in the following GitHub repository: https://github.com/nmaahcdigital/ox/tree/master/sf/draft%20procurement.  
3. The government intends to review responses to this qualifications statement, and will provide the anticipated Request for Proposal to only those vendors whom the government has decided has met the minimum qualifications.  
4. Minimum Qualifications: However, only vendors that respond 'yes' to all of the below bullet points will receive the eventual Request for Proposal and will be allowed to participate in this procurement. Next to each bullet point below, answer 'yes' to indicate that the statement is true for your company or indicate 'no' to indicate that the statement is not completely true for your company.  

The bullet points below ensure that the size of the vendor is adequate for this particular work, and that the anticipated price proposal is in the same 'ballpark' as the government budget.  

* Has your company have adequate size to successfully deliver the digital product (15 FTEs minimum)?
* Does your company certify that it is able to build the product within the budgetary constraints of the Government. See size estimate of team as indicated in the draft Statements of Objectives?

The bullet points below relate back to the Digital Services Playbook.  

[comment]: <> (Added "we" to each; I believe it makes it clearer that respondent should also answer yes/no to these bullets, plus it makes it a little easier to read :D)


Play 1 – We Understand What People Need
  * We have identified the primary users of our service, and we conduct formal user research with these users at least monthly. These users must be real users of the product or service, and must not be a small set of pre-designated Subject Matter Experts.
  
  [comment]: <> (^^ this might be confused with getting client feedback about the agency's/firm's serivces. I might nix this bullet all together and start with the next.)
  
  * Over the last quarter, we have conducted for our clients qualitative research methods (e.g. contextual inquiries, user interviews, on-site observations) with our client’s users and have changed our implementation plan based on the findings.
  * Through user research directly with end-users, we have documented and analyzed findings about user goals, needs, behaviors, and preferences, and continually refer to the findings to shape the product we and our clients built.
  
Play 2 – We Address the Whole Experience from Start to Finish
  * Through direct user research, we understand user motivations as they use the service we provide.
  * We document all the steps users need to go through to achieve an outcome or goal, across any channels (online, in person, on the phone, etc) in a series of journey maps or service blueprints that capture the touchpoints we are responsible for. This includes a “happy path” as well as what happens if something goes wrong.
  * Through research with our client's [comment]: <> (^^ Again, if you're again with digital agencies, their usually not _your_ users. Their your clients. Then again, you may not be only engaging digital agencies.) users and internal service providers, we have identified the pain points in the current way the service is delivered and prioritized these according to greatest user need and internal dependencies.
  * We have built out touchpoints to help a user recover when the service breaks or if their needs fall out of the normal happy path.
  
Play 3 – We Make it Simple and Intuitive
  * The products or services for our clients do not require knowledge of the organizational structure or our agency to complete the process.
  * We coordinated with our clients to make design and content decisions based on user research, usability testing, and analytics.
  * For all user-facing features built over the last quarter, we coordinated with our clients to use plain language that is familiar to the user and easy to understand.
  
Play 4 – We Build the Service Using Agile and Iterative Practices
  * For at least ½ of the projects/products for our clients we launched a functioning “minimum viable product” (MVP) that took no longer than nine(?) months from the beginning of the project, using a “beta” or “test” period if needed.
  * We ensure the individuals building the service (product managers, developers, designers) communicate closely with each other throughout the process using techniques such as daily standups, launch meetings, and team chat tools.
  * We release features and improvements multiple times each month for at least ½ of the projects/products for our clients.
  * We maintain a prioritized list of features and bugs, also known as a “backlog,” in an issue tracker that is accessible by everyone on the project.
  * We use a source code version control system.
  * We use code reviews to ensure quality for each release.

[comment]: <> (No Play 5-6?)

Play 7 – We Bring in Experienced Teams
  * Our company’s teams include product managers who have built and launched user-centered, high-traffic digital services in previous projects.
  * Our company’s teams include user experience designer(s) who have conducted one-on-one sessions with end users to understand user needs and translated those needs into a design for the digital service in previous projects.
  * Our company currently has content strategist(s) who have developed user-centered, plain-language content in previous projects.
  * Our company includes software engineer(s) who have used modern development and operations (DevOps) techniques like continuous integration and continuous deployment.
  
Play 8 – We Choose a Modern Technology Stack
  * We use modern development tools that enable our software engineers to be effective and allow for adoption of emerging tools.
  * We use software frameworks that are commonly used by modern private-sector companies.
  * Our projects have clear, understandable instructions for setting up a local development environment, which a new developer can use to create a working development instance in less than one day.
  * Our application is built using open source software solutions at every layer of the stack.
  
Play 9 – We Deploy in a Flexible Hosting Environment  
  * For at least ¼ of the projects/products for our clients over the last quarter (of a year), any time we provisioned additional servers or instances for production usage, it took less than two hours.
  * In the last quarter, we have verified that for at least ¼ of the projects/products for our clients, the servers or instances automatically scale based on real-time demand, without any human intervention.
  * Half or more of the projects/products for our clients the application is currently deployed in a test environment that mirrors the production environment.
  
Play 10 – We Automate Testing and Deployments
  * Currently, half or more of the projects/products for our clients follow software build processes which automatically run automated tests to verify functionality and prevent bugs or broken functionality from being released.
  
Play 12 – We Use Data to Drive Decisions
  * For our clients we have developed automated alerts based on monitoring.
  * For our clients we have implemented tools to track concurrent users in real-time, and to understand how users, in the aggregate, use our service.
  * For our clients we have established user metrics (e.g. user satisfaction) for the customer’s/client’s service, including baseline measurements, targets, and timeframes.
  
Play 13 – We Default to Open
  * Our customer/client maintains contractual rights to all custom software developed by our company, including the right to publish or reuse it at no additional cost.
  * The source code developed for our customers’/clients’ application is stored in a publicly-visible code repository, and that repository is currently used by existing developers as they build features.
